{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#README\n",
        "In order to use this code you need to use google colab. The project specifies that undergraduate students use datasets 1-5 for classification and datasets 1 and 2 for missing value estimation. Additionally the project mentions that dataset 3 for missing value estimation is a bonus problem for undergraduate students.\n",
        "\n",
        "Once that is understood then you can move on to the next step.\n",
        "\n",
        "The next step is as simple as dragging and dropping the following files into google colabs file section located on the left side of the page appearing as a file icon:\n",
        "- TestData1.txt\n",
        "- TestData2.txt\n",
        "- TestData3.txt\n",
        "- TestData4.txt\n",
        "- TestData5.txt\n",
        "- TrainData1.txt\n",
        "- TrainData2.txt\n",
        "- TrainData3.txt\n",
        "- TrainData4.txt\n",
        "- TrainData5.txt\n",
        "- TrainLabel1.txt\n",
        "- TrainLabel2.txt\n",
        "- TrainLabel3.txt\n",
        "- TrainLabel4.txt\n",
        "- TrainLabel5.txt\n",
        "- MissingData1.txt\n",
        "- MissingData2.txt\n",
        "- MissingData3.txt\n",
        "\n",
        "Once that is completed go to the Runtime tab at the top of the page and select \"Change runtime type\", under \"Hardware Accelerator\" select \"TPU\" and then \"Save\".\n",
        "\n",
        "Finally, go to the Runtime tab once again and select \"Run all\" to run the code.\n",
        "\n",
        "Once the code has finished running you'll see the results outputted in the same Files section with their respective names and numbers. The format will look as such:\n",
        "\n",
        "Imputed_KNN_MissingDataX.txt\n",
        "Imputed_Mean_MissingDataX.txt\n",
        "TestResult_RF_DatasetX.txt\n",
        "TestResult_SVM_DatasetX.txt\n",
        "\n",
        "If you want to download these files you will need to select them individually. Start by hovering over the file you want to download and select the three vertical dots that appear on the right of the file name. The download option will appear, select it and save it onto your desktop."
      ],
      "metadata": {
        "id": "mGf3jpReZfpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### These Are All the Imports Used Throughout the Code"
      ],
      "metadata": {
        "id": "5plWUrvF2O5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n"
      ],
      "metadata": {
        "id": "KR7GPxp6FaGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Following is Part 1: Classification"
      ],
      "metadata": {
        "id": "3slOEix32NOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classification Using Random Forest"
      ],
      "metadata": {
        "id": "DQ_Cs1HY3thX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The Following is the Imputation, Training, and Prediction Results of TrainData1.txt, TrainLabel1.txt, and TestData1.txt\n",
        "1 uses mean imputation"
      ],
      "metadata": {
        "id": "ODTC3ryBg7ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Training Data, Training Label, and Testing Label\n",
        "training_data1 = pd.read_csv(\"TrainData1.txt\", delimiter='\\t', header=None)\n",
        "training_label1 = pd.read_csv(\"TrainLabel1.txt\", header=None)\n",
        "testing_data1 = pd.read_csv(\"TestData1.txt\", delimiter='\\t', header=None)\n",
        "\n",
        "# Replacing the very inconvenient 1.00000000000000e+99 with a better, more convenient NaN\n",
        "training_data1.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "testing_data1.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "\n",
        "# The RandomForestClassifier doesn't take NaN values so the values are imputed\n",
        "# by taking the mean, the value remains equally as meaningless as NaN\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "training_data1_imputed = pd.DataFrame(imputer.fit_transform(training_data1), columns=training_data1.columns)\n",
        "testing_data1_imputed = pd.DataFrame(imputer.transform(testing_data1), columns=training_data1.columns)\n",
        "\n",
        "# Use StratifiedKFold for cross-validation\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Classification Model (Random Forest)\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Perform cross-validation\n",
        "scores1 = cross_val_score(clf, training_data1_imputed, training_label1.values.ravel(), cv=kfold, scoring='accuracy')\n",
        "print(f\"Cross-Validation Scores: {scores1}\")\n",
        "print(f\"Mean accuracy: {np.mean(scores1)}\")\n",
        "\n",
        "# Train the model on the entire training set\n",
        "clf.fit(training_data1_imputed, training_label1.values.ravel())\n",
        "\n",
        "# Test Label Prediction\n",
        "y_testing_prediction = clf.predict(testing_data1_imputed)\n",
        "\n",
        "# Output Results\n",
        "pd.DataFrame(y_testing_prediction).to_csv(\"TestResult_RF_Dataset1.txt\", index=False, header=None)\n",
        "dataset_name = \"Dataset1\"\n",
        "output_file_path = f\"TestResult_RF_{dataset_name}.txt\"\n",
        "print(f\"Test results for {dataset_name} exported to {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OPokllIrOaa",
        "outputId": "c1f23f27-428f-4af6-8cd9-cac74e4cf892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.92 0.88 0.94]\n",
            "Mean accuracy: 0.9133333333333334\n",
            "Test results for Dataset1 exported to TestResult_RF_Dataset1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The following is the Imputation, Training, and Prediction Results of TrainData2, TrainLabel2, and TestData2\n",
        "2 uses KNN imputation"
      ],
      "metadata": {
        "id": "7ksw_wHngBGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset2(data):\n",
        "    # Convert data to numeric format to avoid TypeError\n",
        "    data = data.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n",
        "\n",
        "    # Using KNN Imputation\n",
        "    imputer = KNNImputer(n_neighbors=3)  # You can adjust the number of neighbors as needed\n",
        "    data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "    return data_imputed\n",
        "\n",
        "def train_and_predict2(dataset_name, train_data_file, train_label_file, test_data_file):\n",
        "    # Load the training data\n",
        "    training_data = pd.read_csv(train_data_file, delimiter='\\s+', header=None, engine='python')\n",
        "    training_labels = pd.read_csv(train_label_file, header=None, engine='python').values.ravel()\n",
        "\n",
        "    # Load the testing data\n",
        "    testing_data = pd.read_csv(test_data_file, delimiter='\\s+', header=None)\n",
        "\n",
        "    # Process training and testing data with KNN imputation\n",
        "    training_data_imputed = process_dataset2(training_data)\n",
        "    testing_data_imputed = process_dataset2(testing_data)\n",
        "\n",
        "    # Classification Model (Random Forest)\n",
        "    clf = RandomForestClassifier()\n",
        "\n",
        "    # Use StratifiedKFold for cross-validation\n",
        "    kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "    # Perform cross-validation on the entire training set\n",
        "    scores245 = cross_val_score(clf, training_data_imputed, training_labels, cv=kfold, scoring='accuracy')\n",
        "\n",
        "    # Print the accuracy for each fold\n",
        "    print(f\"Cross-Validation Scores for {dataset_name}: {scores245}\")\n",
        "    print(f\"Mean accuracy: {np.mean(scores245)}\")\n",
        "\n",
        "    # Fit the model on the entire training set\n",
        "    clf.fit(training_data_imputed, training_labels)\n",
        "\n",
        "    # Test Label Prediction\n",
        "    y_testing_prediction = clf.predict(testing_data_imputed)\n",
        "\n",
        "    # Output Results to a Text File\n",
        "    np.savetxt(f\"TestResult_RF_{dataset_name}.txt\", y_testing_prediction, fmt='%d')\n",
        "    output_file_path = f\"TestResult_RF_{dataset_name}.txt\"\n",
        "    print(f\"Test results for {dataset_name} exported to {output_file_path}\")\n",
        "    print()\n",
        "\n",
        "# Call the function for each dataset\n",
        "train_and_predict2(\"Dataset2\", \"TrainData2.txt\", \"TrainLabel2.txt\", \"TestData2.txt\")\n"
      ],
      "metadata": {
        "id": "iDK6X0eNgCzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baefc968-28f9-42d3-dafd-25296708dd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores for Dataset2: [0.96 0.8  0.84 0.84]\n",
            "Mean accuracy: 0.86\n",
            "Test results for Dataset2 exported to TestResult_RF_Dataset2.txt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The Following is the following is the Imputation, Training, and Prediction Results of TrainData3.txt, TrainLabel3.txt, and TestData3.txt\n",
        "3 uses mean imputation"
      ],
      "metadata": {
        "id": "3Em9x5_9hx3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_predict3(dataset_name, train_data_path, train_label_path, test_data_path):\n",
        "    # Loading Training Data, Training Labels, and Test Data\n",
        "    train_data3 = pd.read_csv(train_data_path, delimiter='\\t', header=None)\n",
        "    train_labels3 = pd.read_csv(train_label_path, header=None)\n",
        "    test_data3 = pd.read_csv(test_data_path, delimiter=',', header=None)\n",
        "\n",
        "    # Replace missing values with NaN in the training data\n",
        "    train_data3.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "    test_data3.replace(1000000000, np.nan, inplace=True)\n",
        "\n",
        "    # Impute missing values with KNN\n",
        "    imputer = KNNImputer(n_neighbors=3)  # You can adjust the number of neighbors as needed\n",
        "    training_data3_imputed = pd.DataFrame(imputer.fit_transform(train_data3), columns=train_data3.columns)\n",
        "    test_data3_imputed = pd.DataFrame(imputer.transform(test_data3), columns=test_data3.columns)\n",
        "\n",
        "    # Use StratifiedKFold for cross-validation\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Initialize RandomForestClassifier\n",
        "    clf = RandomForestClassifier()\n",
        "\n",
        "    # Print cross-validation scores\n",
        "    scores3 = cross_val_score(clf, training_data3_imputed, train_labels3.values.ravel(), cv=kfold, scoring='accuracy')\n",
        "    print(f\"Cross-Validation Scores for {dataset_name}: {scores3}\")\n",
        "    print(f\"Mean accuracy: {np.mean(scores3)}\")\n",
        "\n",
        "    # Train the model on the entire training set\n",
        "    clf.fit(training_data3_imputed, train_labels3.values.ravel())\n",
        "\n",
        "    # Predict labels for the testing data\n",
        "    y_testing_prediction = clf.predict(test_data3_imputed)\n",
        "\n",
        "    # Export test results to a text file\n",
        "    output_file_path = f\"TestResult_RF_{dataset_name}.txt\"\n",
        "    pd.DataFrame(y_testing_prediction).to_csv(output_file_path, index=False, header=None)\n",
        "\n",
        "    print(f\"Test results for {dataset_name} exported to {output_file_path}\")\n",
        "\n",
        "# Example usage for Dataset3 with test results and cross-validation scores\n",
        "train_and_predict3(\"Dataset3\", \"TrainData3.txt\", \"TrainLabel3.txt\", \"TestData3.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej_PvCIvabm3",
        "outputId": "1d9da16d-9ce2-451f-ecc3-539deb8c5880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores for Dataset3: [0.30793651 0.31269841 0.31984127 0.32301587 0.32460317]\n",
            "Mean accuracy: 0.3176190476190476\n",
            "Test results for Dataset3 exported to TestResult_RF_Dataset3.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The following is the Imputation, Training, and Prediction Results of TrainData, TrainLabel, and Testdata of 4 and 5.\n",
        "4 and 5 use mean imputation"
      ],
      "metadata": {
        "id": "R1Hlu09dhe3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset45(data):\n",
        "    # Convert data to numeric format to avoid TypeError\n",
        "    data = data.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n",
        "\n",
        "    # Using Mean Imputation\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "    return data_imputed\n",
        "\n",
        "def train_and_predict45(dataset_name, train_data_file, train_label_file, test_data_file):\n",
        "    # Load the training data\n",
        "    training_data = pd.read_csv(train_data_file, delimiter='\\s+', header=None, engine='python')\n",
        "    training_labels = pd.read_csv(train_label_file, header=None, engine='python').values.ravel()\n",
        "\n",
        "    # Load the testing data\n",
        "    testing_data = pd.read_csv(test_data_file, delimiter='\\s+', header=None)\n",
        "\n",
        "    # Process training and testing data\n",
        "    training_data_imputed = process_dataset45(training_data)\n",
        "    testing_data_imputed = process_dataset45(testing_data)\n",
        "\n",
        "    # Classification Model (Random Forest)\n",
        "    clf = RandomForestClassifier()\n",
        "\n",
        "    # Use StratifiedKFold for cross-validation\n",
        "    kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "    # Perform cross-validation on the entire training set\n",
        "    scores245 = cross_val_score(clf, training_data_imputed, training_labels, cv=kfold, scoring='accuracy')\n",
        "\n",
        "    # Print the accuracy for each fold\n",
        "    print(f\"Cross-Validation Scores for {dataset_name}: {scores245}\")\n",
        "    print(f\"Mean accuracy: {np.mean(scores245)}\")\n",
        "\n",
        "    # Fit the model on the entire training set\n",
        "    clf.fit(training_data_imputed, training_labels)\n",
        "\n",
        "    # Test Label Prediction\n",
        "    y_testing_prediction = clf.predict(testing_data_imputed)\n",
        "\n",
        "    # Output Results to a Text File\n",
        "    np.savetxt(f\"TestResult_RF_{dataset_name}.txt\", y_testing_prediction, fmt='%d')\n",
        "    output_file_path = f\"TestResult_RF_{dataset_name}.txt\"\n",
        "    print(f\"Test results for {dataset_name} exported to {output_file_path}\")\n",
        "    print()\n",
        "\n",
        "train_and_predict45(\"Dataset4\", \"TrainData4.txt\", \"TrainLabel4.txt\", \"TestData4.txt\")\n",
        "train_and_predict45(\"Dataset5\", \"TrainData5.txt\", \"TrainLabel5.txt\", \"TestData5.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpXlJh3HQKQl",
        "outputId": "25565454-8252-40a7-fe88-730dfb2734b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores for Dataset4: [0.96546311 0.94976452 0.95761381 0.97484277]\n",
            "Mean accuracy: 0.9619210528914033\n",
            "Test results for Dataset4 exported to TestResult_RF_Dataset4.txt\n",
            "\n",
            "Cross-Validation Scores for Dataset5: [0.58928571 0.69642857 0.65357143 0.65232975]\n",
            "Mean accuracy: 0.6479038658474142\n",
            "Test results for Dataset5 exported to TestResult_RF_Dataset5.txt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classification Using SVM (Support Vector Machine)"
      ],
      "metadata": {
        "id": "rYncYSs5347_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The Following is the Imputation, Training, and Prediction Results of TrainData1.txt, TrainLabel1.txt, and TestData1.txt"
      ],
      "metadata": {
        "id": "WIWT6pwf4CRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Training Data, Training Label, and Testing Label\n",
        "training_data1 = pd.read_csv(\"TrainData1.txt\", delimiter='\\t', header=None)\n",
        "training_label1 = pd.read_csv(\"TrainLabel1.txt\", header=None)\n",
        "testing_data1 = pd.read_csv(\"TestData1.txt\", delimiter='\\t', header=None)\n",
        "\n",
        "# Replacing the very inconvenient 1.00000000000000e+99 with a better, more convenient NaN\n",
        "training_data1.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "testing_data1.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "\n",
        "# The SVM classifier is sensitive to feature scales, so it's a good idea to standardize the data\n",
        "scaler = StandardScaler()\n",
        "training_data1_scaled = pd.DataFrame(scaler.fit_transform(training_data1), columns=training_data1.columns)\n",
        "testing_data1_scaled = pd.DataFrame(scaler.transform(testing_data1), columns=training_data1.columns)\n",
        "\n",
        "# The RandomForestClassifier doesn't take NaN values, so the values are imputed\n",
        "# by taking the mean, the value remains equally as meaningless as NaN\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "training_data1_imputed = pd.DataFrame(imputer.fit_transform(training_data1_scaled), columns=training_data1_scaled.columns)\n",
        "testing_data1_imputed = pd.DataFrame(imputer.transform(testing_data1_scaled), columns=training_data1_scaled.columns)\n",
        "\n",
        "# Use StratifiedKFold for cross-validation\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Classification Model (Support Vector Machine)\n",
        "clf = SVC()\n",
        "\n",
        "# Perform cross-validation\n",
        "scores1 = cross_val_score(clf, training_data1_imputed, training_label1.values.ravel(), cv=kfold, scoring='accuracy')\n",
        "print(f\"Cross-Validation Scores: {scores1}\")\n",
        "print(f\"Mean accuracy: {np.mean(scores1)}\")\n",
        "\n",
        "# Train the model on the entire training set\n",
        "clf.fit(training_data1_imputed, training_label1.values.ravel())\n",
        "\n",
        "# Test Label Prediction\n",
        "y_testing_prediction = clf.predict(testing_data1_imputed)\n",
        "\n",
        "# Output Results\n",
        "pd.DataFrame(y_testing_prediction).to_csv(\"TestResult_SVM_Dataset1.txt\", index=False, header=None)\n",
        "dataset_name = \"Dataset1\"\n",
        "output_file_path = f\"TestResult_SVM_{dataset_name}.txt\"\n",
        "print(f\"Test results for {dataset_name} exported to {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZkoPoEO4U06",
        "outputId": "c2ecd29b-d17e-4fb4-d76d-d3640d70eb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.92 0.86 0.9 ]\n",
            "Mean accuracy: 0.8933333333333334\n",
            "Test results for Dataset1 exported to TestResult_SVM_Dataset1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The following is the Imputation, Training, and Prediction Results of TrainData, TrainLabel, and Testdata of 2, 4, and 5.*italicized text*"
      ],
      "metadata": {
        "id": "seLrrjfv4CPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset245(data):\n",
        "    # Convert data to numeric format to avoid TypeError\n",
        "    data = data.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n",
        "\n",
        "    # Using Mean Imputation\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "    return data_imputed\n",
        "\n",
        "def train_and_predict245(dataset_name, train_data_file, train_label_file, test_data_file):\n",
        "    # Load the training data\n",
        "    training_data = pd.read_csv(train_data_file, delimiter='\\s+', header=None, engine='python')\n",
        "    training_labels = pd.read_csv(train_label_file, header=None, engine='python').values.ravel()\n",
        "\n",
        "    # Load the testing data\n",
        "    testing_data = pd.read_csv(test_data_file, delimiter='\\s+', header=None)\n",
        "\n",
        "    # Process training and testing data\n",
        "    training_data_imputed = process_dataset245(training_data)\n",
        "    testing_data_imputed = process_dataset245(testing_data)\n",
        "\n",
        "    # The SVM classifier is sensitive to feature scales, so it's a good idea to standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    training_data_scaled = pd.DataFrame(scaler.fit_transform(training_data_imputed), columns=training_data_imputed.columns)\n",
        "    testing_data_scaled = pd.DataFrame(scaler.transform(testing_data_imputed), columns=training_data_imputed.columns)\n",
        "\n",
        "    # Classification Model (Support Vector Machine)\n",
        "    clf = SVC()\n",
        "\n",
        "    # Use StratifiedKFold for cross-validation\n",
        "    kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "    # Perform cross-validation on the entire training set\n",
        "    scores245 = cross_val_score(clf, training_data_scaled, training_labels, cv=kfold, scoring='accuracy')\n",
        "\n",
        "    # Print the accuracy for each fold\n",
        "    print(f\"Cross-Validation Scores for {dataset_name}: {scores245}\")\n",
        "    print(f\"Mean accuracy: {np.mean(scores245)}\")\n",
        "\n",
        "    # Fit the model on the entire training set\n",
        "    clf.fit(training_data_scaled, training_labels)\n",
        "\n",
        "    # Test Label Prediction\n",
        "    y_testing_prediction = clf.predict(testing_data_scaled)\n",
        "\n",
        "    # Output Results to a Text File\n",
        "    np.savetxt(f\"TestResult_SVM_{dataset_name}.txt\", y_testing_prediction, fmt='%d')\n",
        "    output_file_path = f\"TestResult_SVM_{dataset_name}.txt\"\n",
        "    print(f\"Test results for {dataset_name} exported to {output_file_path}\")\n",
        "    print()\n",
        "\n",
        "# Call the function for each dataset\n",
        "train_and_predict245(\"Dataset2\", \"TrainData2.txt\", \"TrainLabel2.txt\", \"TestData2.txt\")\n",
        "train_and_predict245(\"Dataset4\", \"TrainData4.txt\", \"TrainLabel4.txt\", \"TestData4.txt\")\n",
        "train_and_predict245(\"Dataset5\", \"TrainData5.txt\", \"TrainLabel5.txt\", \"TestData5.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-cani5r7j3X",
        "outputId": "91a79545-66e8-4daf-a673-78168695b5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores for Dataset2: [0.88 0.84 0.76 0.84]\n",
            "Mean accuracy: 0.83\n",
            "Test results for Dataset2 exported to TestResult_SVM_Dataset2.txt\n",
            "\n",
            "Cross-Validation Scores for Dataset4: [0.89638932 0.89638932 0.90423862 0.91823899]\n",
            "Mean accuracy: 0.9038140655391329\n",
            "Test results for Dataset4 exported to TestResult_SVM_Dataset4.txt\n",
            "\n",
            "Cross-Validation Scores for Dataset5: [0.575      0.62857143 0.60714286 0.59498208]\n",
            "Mean accuracy: 0.601424091141833\n",
            "Test results for Dataset5 exported to TestResult_SVM_Dataset5.txt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The Following is the following is the Imputation, Training, and Prediction Results of TrainData3.txt, TrainLabel3.txt, and TestData3.txt"
      ],
      "metadata": {
        "id": "pJea8PmQ8Sqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_predict3(dataset_name, train_data_path, train_label_path, test_data_path):\n",
        "    # Loading Training Data, Training Labels, and Test Data\n",
        "    train_data3 = pd.read_csv(train_data_path, delimiter='\\t', header=None)\n",
        "    train_labels3 = pd.read_csv(train_label_path, header=None)\n",
        "    test_data3 = pd.read_csv(test_data_path, delimiter=',', header=None)\n",
        "\n",
        "    # Replace missing values with NaN in the training data\n",
        "    train_data3.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "    test_data3.replace(1000000000, np.nan, inplace=True)\n",
        "\n",
        "    # Impute missing values with KNN\n",
        "    imputer = KNNImputer(n_neighbors=3)  # You can adjust the number of neighbors as needed\n",
        "    training_data3_imputed = pd.DataFrame(imputer.fit_transform(train_data3), columns=train_data3.columns)\n",
        "    test_data3_imputed = pd.DataFrame(imputer.transform(test_data3), columns=test_data3.columns)\n",
        "\n",
        "    # The SVM classifier is sensitive to feature scales, so it's a good idea to standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    training_data3_scaled = pd.DataFrame(scaler.fit_transform(training_data3_imputed), columns=training_data3_imputed.columns)\n",
        "    test_data3_scaled = pd.DataFrame(scaler.transform(test_data3_imputed), columns=training_data3_imputed.columns)\n",
        "\n",
        "    # Use StratifiedKFold for cross-validation\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Initialize Support Vector Machine Classifier\n",
        "    clf = SVC()\n",
        "\n",
        "    # Print cross-validation scores\n",
        "    scores3 = cross_val_score(clf, training_data3_scaled, train_labels3.values.ravel(), cv=kfold, scoring='accuracy')\n",
        "    print(f\"Cross-Validation Scores for {dataset_name}: {scores3}\")\n",
        "    print(f\"Mean accuracy: {np.mean(scores3)}\")\n",
        "\n",
        "    # Train the model on the entire training set\n",
        "    clf.fit(training_data3_scaled, train_labels3.values.ravel())\n",
        "\n",
        "    # Predict labels for the testing data\n",
        "    y_testing_prediction = clf.predict(test_data3_scaled)\n",
        "\n",
        "    # Export test results to a text file\n",
        "    output_file_path = f\"TestResult_SVM_{dataset_name}.txt\"\n",
        "    pd.DataFrame(y_testing_prediction).to_csv(output_file_path, index=False, header=None)\n",
        "\n",
        "    print(f\"Test results for {dataset_name} exported to {output_file_path}\")\n",
        "\n",
        "# Example usage for Dataset3 with test results and cross-validation scores\n",
        "train_and_predict3(\"Dataset3\", \"TrainData3.txt\", \"TrainLabel3.txt\", \"TestData3.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SepJq7ak8Vpj",
        "outputId": "a73da16e-53a4-4331-c62d-99de0dba8ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores for Dataset3: [0.32936508 0.32857143 0.35079365 0.34365079 0.33809524]\n",
            "Mean accuracy: 0.3380952380952381\n",
            "Test results for Dataset3 exported to TestResult_SVM_Dataset3.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Following is the Beginning of Part 2: Missing Value Estimation"
      ],
      "metadata": {
        "id": "X3-NbWjOh7tA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Following is the Missing Value Estimation of Dataset1, 2, and 3"
      ],
      "metadata": {
        "id": "CyDk0BCCjFPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Method is the Previously Used Mean Imputation"
      ],
      "metadata": {
        "id": "EYPvkarRk7-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_imputation(file_path):\n",
        "    # Read data from the file\n",
        "    dataset = pd.read_csv(file_path, delimiter='\\s+', header=None)\n",
        "\n",
        "    # Replace 1.00000000000000e+99 with NaN for easier handling\n",
        "    dataset.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "\n",
        "    # Impute missing values with the mean of each column\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    dataset_imputed = pd.DataFrame(imputer.fit_transform(dataset), columns=dataset.columns)\n",
        "\n",
        "    return dataset_imputed\n",
        "\n",
        "# Imputing Dataset 1\n",
        "file_path_dataset1 = \"MissingData1.txt\"\n",
        "dataset1_imputed = mean_imputation(file_path_dataset1)\n",
        "print(\"Imputed Dataset 1:\")\n",
        "print(dataset1_imputed)\n",
        "print()\n",
        "\n",
        "\n",
        "# Imputing Dataset 2\n",
        "file_path_dataset2 = \"MissingData2.txt\"  # Replace with the actual file path\n",
        "dataset2_imputed = mean_imputation(file_path_dataset2)\n",
        "print(\"Imputed Dataset 2:\")\n",
        "print(dataset2_imputed)\n",
        "print()\n",
        "\n",
        "\n",
        "# Imputing Dataset 3\n",
        "file_path_dataset3 = \"MissingData3.txt\"  # Replace with the actual file path\n",
        "dataset3_imputed = mean_imputation(file_path_dataset3)\n",
        "print(\"Imputed Dataset 3:\")\n",
        "print(dataset3_imputed)\n",
        "print()\n",
        "\n",
        "\n",
        "# Saving Imputed Datasets\n",
        "dataset1_imputed.to_csv(\"Imputed_Mean_MissingData1.txt\", sep='\\t', index=False)\n",
        "dataset2_imputed.to_csv(\"Imputed_Mean_MissingData2.txt\", sep='\\t', index=False)\n",
        "dataset3_imputed.to_csv(\"Imputed_Mean_MissingData3.txt\", sep='\\t', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "174FO5PBiCsE",
        "outputId": "48002eda-131d-482c-89f1-af5341109b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputed Dataset 1:\n",
            "       0     1         2         3         4     5     6     7     8     9   \\\n",
            "0   -0.11  0.02 -0.360000 -0.110000  0.480000 -0.20  0.27  0.29 -0.34 -0.05   \n",
            "1   -0.30 -0.37 -0.180000 -0.090000 -0.160000 -0.16 -0.10 -0.09  0.46  0.32   \n",
            "2    0.50  0.18  0.410000  0.007404 -0.014589  0.15 -0.25 -0.41 -0.07 -0.13   \n",
            "3    0.00 -0.11 -0.017806  0.190000  0.000000 -0.07  0.18  0.18 -0.23 -0.16   \n",
            "4    0.40 -0.16  0.310000 -0.340000  0.020000  0.21 -0.70  0.11  0.08  0.05   \n",
            "..    ...   ...       ...       ...       ...   ...   ...   ...   ...   ...   \n",
            "237 -0.45 -0.31 -0.260000 -0.740000 -0.060000  0.09 -0.37  0.38  0.35  0.45   \n",
            "238  0.12 -0.27  0.030000  0.360000  1.090000  0.41  0.15  0.01 -0.22 -0.01   \n",
            "239  1.31  0.05 -0.170000  0.230000 -0.250000 -0.76 -0.06 -0.22  0.36 -0.17   \n",
            "240  0.34  0.03 -0.120000 -0.030000  0.330000 -0.23 -0.08  0.20 -0.08  0.08   \n",
            "241 -0.03 -0.03 -0.220000  0.060000 -0.030000 -0.31  0.01  0.22  0.46  0.24   \n",
            "\n",
            "       10    11    12    13  \n",
            "0    0.23  0.08 -0.45  0.25  \n",
            "1    0.02  0.31  0.40 -0.07  \n",
            "2   -0.15 -0.01 -0.28 -0.09  \n",
            "3    0.03 -0.12 -0.11  0.23  \n",
            "4   -0.09  0.07  0.04 -0.01  \n",
            "..    ...   ...   ...   ...  \n",
            "237  0.13  0.27  0.31  0.19  \n",
            "238 -0.09 -0.55 -0.55 -0.49  \n",
            "239 -0.46 -0.06  0.21 -0.01  \n",
            "240 -0.12 -0.14  0.12 -0.30  \n",
            "241 -0.42  0.21 -0.26  0.10  \n",
            "\n",
            "[242 rows x 14 columns]\n",
            "\n",
            "Imputed Dataset 2:\n",
            "           0         1         2         3         4         5         6   \\\n",
            "0    0.688728 -0.212720  0.498783  0.836527  0.753066 -0.212667  0.942724   \n",
            "1    0.002184  0.110242 -0.219114 -0.007928 -0.126895  0.312428  0.205479   \n",
            "2   -0.738929 -0.109915 -0.584726  0.184901 -0.124804 -0.182223  0.106920   \n",
            "3    0.245575 -0.073991 -0.317213 -0.238237 -0.234355 -0.455127 -0.326878   \n",
            "4    0.239510  0.037124  0.283365  0.047755  0.235801  0.014405  0.403622   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "753  0.147915 -0.146270  0.076802  0.210026  0.200007 -0.177462  0.460558   \n",
            "754 -0.449871  0.465843  0.674586  0.208321  0.208008  0.014405  0.584391   \n",
            "755  0.002184  0.278174  0.005073  0.780210  0.193115  0.185872  1.035979   \n",
            "756  0.240036  0.114697  0.048121  0.598281  0.140374  0.210312  0.879964   \n",
            "757 -0.344451 -0.005629 -0.486805 -0.655308 -0.536342 -0.337252 -0.589607   \n",
            "\n",
            "           7         8         9   ...        40        41        42  \\\n",
            "0   -0.452367 -0.077101  0.167050  ...  0.179593  0.694768  0.617762   \n",
            "1    0.228858  0.270159  0.152407  ... -0.231804 -0.004617 -0.483945   \n",
            "2   -0.280529  0.270159 -0.379498  ... -0.278944 -0.178492 -0.109231   \n",
            "3   -0.493662 -0.123100 -0.380940  ...  0.353774  0.285639  0.233876   \n",
            "4   -0.216095 -0.247166  0.167056  ...  0.237784  0.439557 -0.006479   \n",
            "..        ...       ...       ...  ...       ...       ...       ...   \n",
            "753  0.003164  0.393134  0.211305  ...  0.019922  0.591618  0.128843   \n",
            "754 -0.081353  0.523234 -0.790732  ... -0.075985  0.105754  1.093120   \n",
            "755 -0.073586  0.202814  0.412057  ...  0.076009  0.814107  0.298956   \n",
            "756 -0.051509  0.498237  0.373390  ... -0.049314  0.785388  0.194695   \n",
            "757 -0.380977  0.097221 -0.667712  ... -0.732214 -0.363007 -0.579639   \n",
            "\n",
            "           43        44        45        46        47        48        49  \n",
            "0   -0.040676  0.067808  0.032745  0.701679  0.272815  0.242996  0.044602  \n",
            "1   -0.056103 -0.324140 -0.152420 -0.259235 -0.152041 -0.487165 -0.600970  \n",
            "2   -0.030136 -0.276224 -0.160540 -0.222567  0.023728 -0.180418 -0.247854  \n",
            "3    0.088700 -0.025839 -0.322532  0.433586  0.323603  0.360877  0.236961  \n",
            "4   -0.157518 -0.150361  0.063090  0.761268  0.321644  0.199316 -0.023753  \n",
            "..        ...       ...       ...       ...       ...       ...       ...  \n",
            "753  0.041614  0.137797 -0.024003  0.646414  0.056936  0.157091 -0.247854  \n",
            "754  0.670867 -0.150361  0.261048  0.386092  0.494591  1.053865 -0.247854  \n",
            "755 -0.023306 -0.150361  0.008666  0.223829  0.196888  0.163755 -0.406924  \n",
            "756  0.055395  0.223582  0.562165  0.527863  0.415455 -0.029304 -0.447356  \n",
            "757 -0.684276 -0.109037  0.031219 -0.273434 -0.121937 -0.029304 -0.247854  \n",
            "\n",
            "[758 rows x 50 columns]\n",
            "\n",
            "Imputed Dataset 3:\n",
            "            0          1         2          3         4         5         6   \\\n",
            "0    10.145677   4.357071  6.374937   8.646739  7.446256   6.89985  6.969927   \n",
            "1    11.000000   4.357071  6.374937   8.000000  7.000000  10.00000  6.000000   \n",
            "2    11.861707   4.357071  6.374937   7.146087  8.862947   6.89985  6.969927   \n",
            "3    11.999000  10.000000  6.374937  11.000000  6.405992   6.89985  4.000000   \n",
            "4    10.000000   4.357071  6.374937   9.000000  7.584963   6.89985  7.000000   \n",
            "..         ...        ...       ...        ...       ...       ...       ...   \n",
            "268   7.075052   4.357071  6.374937   7.146087  7.516798   6.89985  6.969927   \n",
            "269   7.075052   4.357071  6.374937   7.146087  7.516798   6.89985  6.969927   \n",
            "270   7.075052   4.357071  6.374937   7.146087  7.516798   6.89985  6.969927   \n",
            "271   7.075052   4.357071  6.374937   7.146087  7.516798   6.89985  6.969927   \n",
            "272   7.075052   4.357071  6.374937   7.146087  7.516798   6.89985  6.969927   \n",
            "\n",
            "           7         8        9   ...        69        70         71  \\\n",
            "0    6.655352  6.856803  6.32128  ...  7.400965  9.510461  10.005356   \n",
            "1    6.000000  6.856803  4.00000  ...  7.400965  9.510461  10.005356   \n",
            "2    7.574050  5.000000  5.00000  ...  7.400965  9.510461  10.005356   \n",
            "3    7.574050  4.000000  6.32128  ...  7.400965  9.510461  10.005356   \n",
            "4    8.000000  6.856803  6.32128  ...  7.400965  9.510461  10.005356   \n",
            "..        ...       ...      ...  ...       ...       ...        ...   \n",
            "268  7.574050  6.856803  6.32128  ...  7.400965  9.510461  10.596136   \n",
            "269  7.574050  6.856803  6.32128  ...  7.400965  7.546729   7.094387   \n",
            "270  7.574050  6.856803  6.32128  ...  7.400965  9.546729  10.596136   \n",
            "271  7.574050  6.856803  6.32128  ...  7.400965  9.546729   9.596136   \n",
            "272  7.574050  6.856803  6.32128  ...  7.400965  8.708617   8.888918   \n",
            "\n",
            "            72         73         74         75         76         77  \\\n",
            "0    10.668227   9.724256  10.586870   7.815748  10.679127   9.243779   \n",
            "1    10.668227   9.724256  10.586870   7.815748  10.679127   9.243779   \n",
            "2    10.668227   9.724256  10.586870   7.815748  10.679127   9.243779   \n",
            "3    10.668227   9.724256  10.586870   7.815748  10.679127   9.243779   \n",
            "4    10.668227   9.724256  10.586870   7.815748  10.679127   9.243779   \n",
            "..         ...        ...        ...        ...        ...        ...   \n",
            "268  11.611122  11.073963  11.169925   7.333421  10.679127   9.592793   \n",
            "269   6.611122   9.724256   7.000000  10.666576  10.679127  11.118593   \n",
            "270  10.668227  10.736966  10.586870  11.999000  10.679127  11.999000   \n",
            "271  10.668227   9.222392  10.586870  11.000178  10.679127  11.452195   \n",
            "272  10.388729   9.070389  10.586870  11.723375  10.679127  11.999000   \n",
            "\n",
            "            78  \n",
            "0     9.011024  \n",
            "1     9.011024  \n",
            "2     9.011024  \n",
            "3     9.011024  \n",
            "4     9.011024  \n",
            "..         ...  \n",
            "268  11.999000  \n",
            "269   9.081794  \n",
            "270  10.286635  \n",
            "271   8.081794  \n",
            "272   9.620586  \n",
            "\n",
            "[273 rows x 79 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second Method is the KNN (K-Nearest Neighbors) Method of Imputation"
      ],
      "metadata": {
        "id": "QgAasjPJlRW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_imputation(file_path, n_neighbors=5):\n",
        "    # Read data from the file\n",
        "    dataset = pd.read_csv(file_path, delimiter='\\s+', header=None)\n",
        "\n",
        "    # Replace 1.00000000000000e+99 with NaN for easier handling\n",
        "    dataset.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "\n",
        "    # Impute missing values with K-Nearest Neighbors\n",
        "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
        "    dataset_imputed = pd.DataFrame(imputer.fit_transform(dataset), columns=dataset.columns)\n",
        "\n",
        "    return dataset_imputed\n",
        "\n",
        "# Example usage for Dataset 1 with KNN imputation\n",
        "file_path_dataset1 = \"MissingData1.txt\"\n",
        "dataset1_imputed_knn = knn_imputation(file_path_dataset1)\n",
        "print(\"KNN Imputed Dataset 1:\")\n",
        "print(dataset1_imputed_knn)\n",
        "print()\n",
        "\n",
        "# Example usage for Dataset 2 with KNN imputation\n",
        "file_path_dataset2 = \"MissingData2.txt\"  # Replace with the actual file path\n",
        "dataset2_imputed_knn = knn_imputation(file_path_dataset2)\n",
        "print(\"KNN Imputed Dataset 2:\")\n",
        "print(dataset2_imputed_knn)\n",
        "print()\n",
        "\n",
        "# Example usage for Dataset 3 with KNN imputation\n",
        "file_path_dataset3 = \"MissingData3.txt\"  # Replace with the actual file path\n",
        "dataset3_imputed_knn = knn_imputation(file_path_dataset3)\n",
        "print(\"KNN Imputed Dataset 3:\")\n",
        "print(dataset3_imputed_knn)\n",
        "print()\n",
        "\n",
        "# Saving KNN Imputed Datasets\n",
        "dataset1_imputed_knn.to_csv(\"Imputed_KNN_MissingData1.txt\", sep='\\t', index=False)\n",
        "dataset2_imputed_knn.to_csv(\"Imputed_KNN_MissingData2.txt\", sep='\\t', index=False)\n",
        "dataset3_imputed_knn.to_csv(\"Imputed_KNN_MissingData3.txt\", sep='\\t', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZdpODMMleCC",
        "outputId": "11028107-bfa5-4260-c5bf-71374401be20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Imputed Dataset 1:\n",
            "       0     1      2      3      4     5     6     7     8     9     10  \\\n",
            "0   -0.11  0.02 -0.360 -0.110  0.480 -0.20  0.27  0.29 -0.34 -0.05  0.23   \n",
            "1   -0.30 -0.37 -0.180 -0.090 -0.160 -0.16 -0.10 -0.09  0.46  0.32  0.02   \n",
            "2    0.50  0.18  0.410  0.028  0.176  0.15 -0.25 -0.41 -0.07 -0.13 -0.15   \n",
            "3    0.00 -0.11 -0.062  0.190  0.000 -0.07  0.18  0.18 -0.23 -0.16  0.03   \n",
            "4    0.40 -0.16  0.310 -0.340  0.020  0.21 -0.70  0.11  0.08  0.05 -0.09   \n",
            "..    ...   ...    ...    ...    ...   ...   ...   ...   ...   ...   ...   \n",
            "237 -0.45 -0.31 -0.260 -0.740 -0.060  0.09 -0.37  0.38  0.35  0.45  0.13   \n",
            "238  0.12 -0.27  0.030  0.360  1.090  0.41  0.15  0.01 -0.22 -0.01 -0.09   \n",
            "239  1.31  0.05 -0.170  0.230 -0.250 -0.76 -0.06 -0.22  0.36 -0.17 -0.46   \n",
            "240  0.34  0.03 -0.120 -0.030  0.330 -0.23 -0.08  0.20 -0.08  0.08 -0.12   \n",
            "241 -0.03 -0.03 -0.220  0.060 -0.030 -0.31  0.01  0.22  0.46  0.24 -0.42   \n",
            "\n",
            "       11    12    13  \n",
            "0    0.08 -0.45  0.25  \n",
            "1    0.31  0.40 -0.07  \n",
            "2   -0.01 -0.28 -0.09  \n",
            "3   -0.12 -0.11  0.23  \n",
            "4    0.07  0.04 -0.01  \n",
            "..    ...   ...   ...  \n",
            "237  0.27  0.31  0.19  \n",
            "238 -0.55 -0.55 -0.49  \n",
            "239 -0.06  0.21 -0.01  \n",
            "240 -0.14  0.12 -0.30  \n",
            "241  0.21 -0.26  0.10  \n",
            "\n",
            "[242 rows x 14 columns]\n",
            "\n",
            "KNN Imputed Dataset 2:\n",
            "           0         1         2         3         4         5         6   \\\n",
            "0    0.688728 -0.212720  0.498783  0.836527  0.753066 -0.212667  0.942724   \n",
            "1    0.135022  0.110242 -0.219114 -0.007928 -0.126895  0.312428  0.205479   \n",
            "2   -0.738929 -0.109915 -0.584726  0.184901 -0.124804 -0.182223  0.106920   \n",
            "3    0.245575 -0.073991 -0.317213 -0.238237 -0.234355 -0.455127 -0.326878   \n",
            "4    0.239510  0.106049  0.283365  0.047755  0.235801  0.077804  0.442455   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "753  0.147915 -0.146270  0.076802  0.349336  0.200007 -0.177462  0.460558   \n",
            "754 -0.449871  0.465843  0.674586  0.208321  0.208008  0.188563  0.584391   \n",
            "755  0.476387  0.278174  0.005073  0.780210  0.193115  0.185872  1.035979   \n",
            "756  0.240036  0.114697  0.098368  0.598281  0.140374  0.210312  0.879964   \n",
            "757 -0.344451 -0.005629 -0.486805 -0.655308 -0.536342 -0.337252 -0.589607   \n",
            "\n",
            "           7         8         9   ...        40        41        42  \\\n",
            "0   -0.452367 -0.077101  0.314517  ...  0.179593  0.694768  0.617762   \n",
            "1    0.228858  0.267490  0.152407  ... -0.231804 -0.004617 -0.483945   \n",
            "2   -0.280529  0.067550 -0.379498  ... -0.278944 -0.178492 -0.109231   \n",
            "3   -0.493662 -0.123100 -0.380940  ...  0.353774  0.285639  0.233876   \n",
            "4   -0.216095 -0.247166  0.167056  ...  0.237784  0.439557 -0.006479   \n",
            "..        ...       ...       ...  ...       ...       ...       ...   \n",
            "753  0.003164  0.393134  0.211305  ...  0.019922  0.591618  0.128843   \n",
            "754 -0.081353  0.523234 -0.790732  ... -0.075985  0.105754  1.093120   \n",
            "755 -0.073586  0.202814  0.412057  ...  0.076009  0.814107  0.298956   \n",
            "756 -0.051509  0.498237  0.373390  ... -0.049314  0.785388  0.194695   \n",
            "757 -0.380977  0.097221 -0.667712  ... -0.732214 -0.363007 -0.579639   \n",
            "\n",
            "           43        44        45        46        47        48        49  \n",
            "0   -0.040676  0.067808  0.032745  0.701679  0.272815  0.242996  0.044602  \n",
            "1   -0.056103 -0.324140 -0.152420 -0.259235 -0.152041 -0.487165 -0.600970  \n",
            "2   -0.030136 -0.276224 -0.273967 -0.222567 -0.187063 -0.180418 -0.153375  \n",
            "3    0.088700 -0.025839 -0.322532  0.433586  0.323603  0.360877  0.236961  \n",
            "4   -0.157518  0.007819  0.063090  0.761268  0.321644  0.199316 -0.023753  \n",
            "..        ...       ...       ...       ...       ...       ...       ...  \n",
            "753  0.041614  0.137797 -0.024003  0.646414  0.056936  0.157091 -0.251973  \n",
            "754  0.670867  0.419592  0.261048  0.386092  0.494591  1.053865  0.459263  \n",
            "755 -0.023306  0.051892  0.008666  0.599856  0.196888  0.163755 -0.406924  \n",
            "756  0.055395  0.223582  0.562165  0.527863  0.415455  0.238826 -0.447356  \n",
            "757 -0.684276 -0.109037  0.031219 -0.273434 -0.121937  0.207948 -0.350394  \n",
            "\n",
            "[758 rows x 50 columns]\n",
            "\n",
            "KNN Imputed Dataset 3:\n",
            "            0        1       2          3         4        5         6   \\\n",
            "0    10.145677   6.1998  7.3998   8.646739  7.446256   6.0000  7.224891   \n",
            "1    11.000000   4.4000  8.5998   8.000000  7.000000  10.0000  6.000000   \n",
            "2    11.861707   6.7998  8.1998   8.999938  8.862947   7.2000  7.460399   \n",
            "3    11.999000  10.0000  5.8000  11.000000  6.405992   7.2000  4.000000   \n",
            "4    10.000000   6.1998  8.1998   9.000000  7.584963   8.5998  7.000000   \n",
            "..         ...      ...     ...        ...       ...      ...       ...   \n",
            "268   5.000000   4.4000  5.0000   5.800000  4.000000   5.0000  4.000000   \n",
            "269   5.553107   3.0000  5.0000   5.800000  4.000000   5.0000  4.000000   \n",
            "270   5.553107   4.4000  5.0000   5.800000  4.000000   5.0000  4.000000   \n",
            "271   6.952907   4.4000  6.0000   5.800000  5.868997   6.9998  4.000000   \n",
            "272   5.553107   4.4000  6.2000   5.800000  4.000000   6.6000  4.000000   \n",
            "\n",
            "           7    8    9   ...        69         70         71         72  \\\n",
            "0    6.655352  5.0  4.2  ...  5.171969   9.681822  10.329487   9.999842   \n",
            "1    6.000000  5.0  4.0  ...  6.767226   8.370643   9.321234  10.574548   \n",
            "2    6.797483  5.0  5.0  ...  4.467257   9.681822  10.329487   9.999842   \n",
            "3    6.482812  4.0  5.0  ...  5.400000   8.970102   8.954342   9.696871   \n",
            "4    8.000000  5.0  5.0  ...  5.755813   9.681822  10.329487   9.999842   \n",
            "..        ...  ...  ...  ...       ...        ...        ...        ...   \n",
            "268  6.281198  5.0  4.0  ...  7.571907  10.887765  10.596136  11.611122   \n",
            "269  9.699708  5.0  4.2  ...  5.184547   7.546729   7.094387   6.611122   \n",
            "270  5.600000  5.0  4.2  ...  7.043103   9.546729  10.596136  10.129218   \n",
            "271  6.281198  5.0  5.2  ...  4.304712   9.546729   9.596136  10.129218   \n",
            "272  6.000000  5.0  4.2  ...  6.843103   8.708617   8.888918  10.388729   \n",
            "\n",
            "            73         74         75         76         77         78  \n",
            "0     9.354057  10.586870   8.466519  10.716793   9.028133   8.906291  \n",
            "1     9.636350  10.648667   9.920840  10.433785  10.004214   8.431075  \n",
            "2     9.354057  10.586870   8.466519  10.716793   9.028133   8.906291  \n",
            "3     9.371964   9.814682   9.654355  10.433785  10.628133   8.631216  \n",
            "4     9.354057  10.586870   8.466519  10.716793   9.028133   8.906291  \n",
            "..         ...        ...        ...        ...        ...        ...  \n",
            "268  11.073963  11.169925   7.333421  11.033785   9.592793  11.999000  \n",
            "269   9.371964   7.000000  10.666576  10.433785  11.118593   9.081794  \n",
            "270  10.736966  10.565998  11.999000  10.633985  11.999000  10.286635  \n",
            "271   9.222392  10.150778  11.000178  10.633985  11.452195   8.081794  \n",
            "272   9.070389  10.150778  11.723375  10.633985  11.999000   9.620586  \n",
            "\n",
            "[273 rows x 79 columns]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}